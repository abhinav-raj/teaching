{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Exploration and Distance/Similarity Computing\n",
    "\n",
    "Anaconda: https://www.anaconda.com/  \n",
    "Anaconda Download: https://www.anaconda.com/distribution/#download-section  \n",
    "Anaconda Install: https://docs.anaconda.com/anaconda/install/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Summary Statistics\n",
    "\n",
    "Summary statistics are quantities, such as the mean and standard deviation, that capture various characteristics of a potentially large set of values with a single number or a small set of numbers. In this tutorial, we will use the Iris sample data, which contains information on 150 Iris flowers, 50 each from one of three Iris species: Setosa, Versicolour, and Virginica. Each flower is characterized by five attributes:\n",
    "\n",
    "- sepal length in centimeters\n",
    "\n",
    "- sepal width in centimeters\n",
    "\n",
    "- petal length in centimeters\n",
    "\n",
    "- petal width in centimeters\n",
    "\n",
    "- class (Setosa, Versicolour, Virginica) \n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "- Load a CSV data file into a Pandas DataFrame object.\n",
    "\n",
    "- Compute various summary statistics from the DataFrame.\n",
    "\n",
    "To execute the sample program shown here, make sure you have installed the Pandas library (see Module 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** First, you need to download the <a href=\"http://archive.ics.uci.edu/ml/datasets/Iris\">Iris dataset</a> from the UCI machine learning repository.\n",
    "\n",
    "**<font color='red'>Code:</font>** The following code uses Pandas to read the CSV file and store them in a DataFrame object named data. Next, it will display the first five rows of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('https://github.com/liuhoward/teaching/raw/master/business_intelligence/iris.data',header=None)\n",
    "data.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** For each quantitative attribute, calculate its average, standard deviation, minimum, and maximum values.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "for col in data.columns:\n",
    "    if is_numeric_dtype(data[col]):\n",
    "        print('%s:' % (col))\n",
    "        print('\\t Mean = %.2f' % data[col].mean())\n",
    "        print('\\t Standard deviation = %.2f' % data[col].std())\n",
    "        print('\\t Minimum = %.2f' % data[col].min())\n",
    "        print('\\t Maximum = %.2f' % data[col].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** For the qualitative attribute (class), count the frequency for each of its distinct values.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** It is also possible to display the summary for all the attributes simultaneously in a table using the describe() function. If an attribute is quantitative, it will display its mean, standard deviation and various quantiles (including minimum, median, and maximum) values. If an attribute is qualitative, it will display its number of unique values and the top (most frequent) values. \n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that count refers to the number of non-missing values for each attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** For multivariate statistics, you can compute the covariance and correlation between pairs of attributes.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariance:')\n",
    "data.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlation:')\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Visualization\n",
    "\n",
    "Data visualization is the display of information in a graphic or tabular format. Successful visualization requires that the data (information) be converted into a visual format so that the characteristics of the data and the relationships\n",
    "among data items or attributes can be analyzed or reported.\n",
    "\n",
    "In this tutorial, you will learn how to display the Iris data created in Section 3.1. To execute the sample program shown here, make sure you have installed the matplotlib library package (see Module 0 on how to install Python packages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** First, we will display the histogram for the sepal length attribute by discretizing it into 8 separate bins and counting the frequency for each bin.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "data['sepal length'].hist(bins=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** A boxplot can also be used to show the distribution of values for each attribute.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot(figsize=(10, 10), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** For each pair of attributes, we can use a scatter plot to visualize their joint distribution.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12,12))\n",
    "index = 0\n",
    "for i in range(3):\n",
    "    for j in range(i+1,4):\n",
    "        ax1 = int(index/2)\n",
    "        ax2 = index % 2\n",
    "        axes[ax1][ax2].scatter(data[data.columns[i]], data[data.columns[j]], color='red')\n",
    "        axes[ax1][ax2].set_xlabel(data.columns[i])\n",
    "        axes[ax1][ax2].set_ylabel(data.columns[j])\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Parallel coordinates can be used to display all the data points simultaneously. Parallel coordinates have one coordinate axis for each attribute, but the different axes are parallel to one other instead of perpendicular, as is traditional. Furthermore, an object is represented as a line instead of as a point. In the example below, the distribution of values for each class can be identified in a separate color.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "%matplotlib inline\n",
    "\n",
    "parallel_coordinates(data, 'class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Distance/Similarity\n",
    "\n",
    "We will compute Euclidean distance, Manhattan, Minkowski (r=3) distance, Jaccard and Cosine (after binarization), Pearson Correlation with Iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select subset data\n",
    "\n",
    "subset = data.iloc[0:10, 0:4]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# calulate euclidean distances as a matrix\n",
    "pairwise_distances(subset, metric='euclidean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale attribute value to [0,1]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scale_subset = min_max_scaler.fit_transform(subset)\n",
    "scale_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate euclidean distance with the scaled data\n",
    "pairwise_distances(scale_subset, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calulate manhattan distances as a matrix\n",
    "pairwise_distances(subset, metric='manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minkowski (r=3) distance\n",
    "pairwise_distances(subset, metric='minkowski', p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "subset_binary = (binarize(subset, threshold=3.2)).astype(int)\n",
    "subset_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calulate jaccard similarity as a matrix\n",
    "1 - pairwise_distances(subset_binary, metric='jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# calulate cosine similarity as a matrix\n",
    "cosine_similarity(subset_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson Correlation with Iris subset\n",
    "subset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Summary\n",
    "\n",
    "This tutorial presents several examples for data exploration, visualization, distance/similarity computing using the Pandas and matplotlib library packages available in Python. \n",
    "\n",
    "**<font color='blue'>References:</font>**\n",
    "\n",
    "1. Documentation on Pandas. https://pandas.pydata.org/\n",
    "2. Documentation on matplotlib. https://matplotlib.org/\n",
    "3. Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
